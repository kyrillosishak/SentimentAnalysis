{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM/LPMAJ/V7mwXm3Q13hK/c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kyrillosishak/SentimentAnalysis/blob/main/SentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IL5cJRsiOFf7",
        "outputId": "59939f58-99ed-47a1-8fe6-4f480f79fbdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1aucr_u_8sKcfuDNhFbB6IzbpOsInHd9d\n",
            "To: /content/kaggle.json\n",
            "\r  0% 0.00/69.0 [00:00<?, ?B/s]\r100% 69.0/69.0 [00:00<00:00, 324kB/s]\n"
          ]
        }
      ],
      "source": [
        "! gdown 1aucr_u_8sKcfuDNhFbB6IzbpOsInHd9d\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d bittlingmayer/amazonreviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVld2Z4KOHFx",
        "outputId": "49f0c707-addc-480d-f45c-af637949322c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading amazonreviews.zip to /content\n",
            "100% 493M/493M [00:14<00:00, 43.4MB/s]\n",
            "100% 493M/493M [00:14<00:00, 34.8MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip amazonreviews.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNU0X0pQOkMQ",
        "outputId": "c06a4f0b-349e-43a9-8fc0-abd9d0b2669c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  amazonreviews.zip\n",
            "  inflating: test.ft.txt.bz2         \n",
            "  inflating: train.ft.txt.bz2        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bzip2 -dk train.ft.txt.bz2"
      ],
      "metadata": {
        "id": "pM7IrFbcO7GK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/"
      ],
      "metadata": {
        "id": "F1VsZou_PTiN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "# Check if a GPU is available, and use it if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "pVy0zN5Kp7pv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if a GPU is available, and use it if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "zTnUA7GCuYwT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdJTpziSugPS",
        "outputId": "ea3043ee-6a41-4334-e347-a4f5cd27d225"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path where the text is stored\n",
        "file_path = '/content/train.ft.txt'\n",
        "\n",
        "# Read the text from the file\n",
        "with open(file_path, 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Split the text into lines based on the '__label__' delimiter\n",
        "lines = text.split('\\n__label__')[1:]\n",
        "\n",
        "# Initialize lists to store labels, subjects, and reviews\n",
        "labels = []\n",
        "subjects = []\n",
        "reviews = []\n",
        "Count = 0\n",
        "# Split each line into label, subject, and review\n",
        "for line in lines:\n",
        "    if Count >= 719999:\n",
        "      break\n",
        "    label, review = line.split(' ', 1)\n",
        "    labels.append(int(label) - 1)\n",
        "\n",
        "    # Extract subject from review\n",
        "    subject, review = review.split(': ', 1)\n",
        "    subjects.append(subject)\n",
        "\n",
        "    no_punctuation = re.sub(r'[\\W]', r' ', review.lower())\n",
        "    no_non_ascii = re.sub(r'[^a-z0-1\\s]', r'', no_punctuation)\n",
        "    reviews.append(no_non_ascii)\n",
        "    Count+=1\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Label': labels, 'Subject': subjects, 'Review': reviews})\n",
        "del labels\n",
        "del subjects\n",
        "del reviews\n",
        "del text\n",
        "del lines"
      ],
      "metadata": {
        "id": "Iwm6fXcPqKCv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the DataFrame\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmje2g0_qhfm",
        "outputId": "1eb360fe-fb53-49bf-869a-dd5ec0e8def0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Label                                            Subject  \\\n",
            "0      1              The best soundtrack ever to anything.   \n",
            "1      1                                           Amazing!   \n",
            "2      1                               Excellent Soundtrack   \n",
            "3      1  Remember, Pull Your Jaw Off The Floor After He...   \n",
            "4      1                            an absolute masterpiece   \n",
            "\n",
            "                                              Review  \n",
            "0  i m reading a lot of reviews saying that this ...  \n",
            "1  this soundtrack is my favorite music of all ti...  \n",
            "2  i truly like this soundtrack and i enjoy video...  \n",
            "3  if you ve played the game  you know how divine...  \n",
            "4  i am quite sure any of you actually taking the...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=0.2, random_state=42)  # You can change the random_state for reproducibility\n"
      ],
      "metadata": {
        "id": "zqecQn2g0c6M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "EfeMqO430hdl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "pVUc-InB010x",
        "outputId": "4d3b957a-5632-4ed9-990a-02d36577fa11"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Label                                            Subject  \\\n",
              "0          1     An illuminating, touching and very funny read.   \n",
              "1          0                                 Silly.............   \n",
              "2          1                                          Gorgeous!   \n",
              "3          0                   loved my old zyliss press but...   \n",
              "4          1                    One Of My Most Favorite Movies!   \n",
              "...      ...                                                ...   \n",
              "28795      1                        More than thought provoking   \n",
              "28796      0                     Guess I did not read the label   \n",
              "28797      0              Only use if original pins are broken.   \n",
              "28798      1                                         Fibblestax   \n",
              "28799      0  Factually incorrect, knowledge of Hindi highly...   \n",
              "\n",
              "                                                  Review  \n",
              "0      when i discovered that bradford dillman had wr...  \n",
              "1      aside from the two attractive leads there is l...  \n",
              "2      got these from my husband for christmas and th...  \n",
              "3      had a zyliss press for years that we loved   t...  \n",
              "4      i saw it on the amazon prime free instant play...  \n",
              "...                                                  ...  \n",
              "28795  my sister in law recommended this film to me  ...  \n",
              "28796  clover honey with lavender flavor injected  no...  \n",
              "28797  i ordered these to replace my worn pins on my ...  \n",
              "28798  wonderful thought filled heart lifting story o...  \n",
              "28799  as a student of cinema and history  i am amaze...  \n",
              "\n",
              "[28800 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7fe1320-6067-466d-bcb3-003a40a51fd8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Subject</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>An illuminating, touching and very funny read.</td>\n",
              "      <td>when i discovered that bradford dillman had wr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Silly.............</td>\n",
              "      <td>aside from the two attractive leads there is l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Gorgeous!</td>\n",
              "      <td>got these from my husband for christmas and th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>loved my old zyliss press but...</td>\n",
              "      <td>had a zyliss press for years that we loved   t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>One Of My Most Favorite Movies!</td>\n",
              "      <td>i saw it on the amazon prime free instant play...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28795</th>\n",
              "      <td>1</td>\n",
              "      <td>More than thought provoking</td>\n",
              "      <td>my sister in law recommended this film to me  ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28796</th>\n",
              "      <td>0</td>\n",
              "      <td>Guess I did not read the label</td>\n",
              "      <td>clover honey with lavender flavor injected  no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28797</th>\n",
              "      <td>0</td>\n",
              "      <td>Only use if original pins are broken.</td>\n",
              "      <td>i ordered these to replace my worn pins on my ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28798</th>\n",
              "      <td>1</td>\n",
              "      <td>Fibblestax</td>\n",
              "      <td>wonderful thought filled heart lifting story o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28799</th>\n",
              "      <td>0</td>\n",
              "      <td>Factually incorrect, knowledge of Hindi highly...</td>\n",
              "      <td>as a student of cinema and history  i am amaze...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28800 rows Ã— 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7fe1320-6067-466d-bcb3-003a40a51fd8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d7fe1320-6067-466d-bcb3-003a40a51fd8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d7fe1320-6067-466d-bcb3-003a40a51fd8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e58ae752-f0b1-4d08-83df-b915eaf1d51b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e58ae752-f0b1-4d08-83df-b915eaf1d51b')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e58ae752-f0b1-4d08-83df-b915eaf1d51b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(df['Review'], df['Label'], train_size=0.75)\n",
        "del df\n",
        "# Initialize a CountVectorizer\n",
        "cv = CountVectorizer(binary=True)\n",
        "cv.fit(X_train)\n",
        "\n",
        "# Transform the text data into feature vectors\n",
        "X_train = cv.transform(X_train)\n",
        "X_val = cv.transform(X_val)"
      ],
      "metadata": {
        "id": "fZlmN93Aqntz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch tensors from your data\n",
        "X_train = torch.tensor(X_train.toarray(), dtype=torch.float32).to(device)\n",
        "X_val = torch.tensor(X_val.toarray(), dtype=torch.float32).to(device)\n",
        "y_train = torch.tensor(y_train.values, dtype=torch.int64).to(device)\n",
        "y_val = torch.tensor(y_val.values, dtype=torch.int64).to(device)"
      ],
      "metadata": {
        "id": "gee7tSqNxomN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create PyTorch data loaders\n",
        "batch_size = 64\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "val_dataset = TensorDataset(X_val, y_val)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "v3bCUYW5-OVY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a logistic regression model in PyTorch and move it to GPU\n",
        "class LogisticRegressionModel(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super(LogisticRegressionModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ZJxDO9QXqwL2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your logistic regression model\n",
        "input_size = X_train.shape[1]\n",
        "num_classes = 2  # Two classes: positive and negative\n",
        "\n",
        "model = LogisticRegressionModel(input_size, num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 40\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch_x, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_x)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_outputs = model(X_val)\n",
        "        _, predicted = torch.max(val_outputs, 1)\n",
        "        val_accuracy = accuracy_score(y_val.cpu().numpy(), predicted.cpu().numpy())\n",
        "        print(f'Epoch [{epoch + 1}/{num_epochs}], Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
        "\n",
        "# Testing the model\n",
        "test_outputs = model(X_val)\n",
        "_, predicted = torch.max(test_outputs, 1)\n",
        "test_accuracy = accuracy_score(y_val.cpu().numpy(), predicted.cpu().numpy())\n",
        "print(f'Test Accuracy: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M1muDmGmnsY",
        "outputId": "be0ae9d0-29c1-4972-f1be-c9a9fe1f86a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/40], Validation Accuracy: 74.49%\n",
            "Epoch [2/40], Validation Accuracy: 75.90%\n",
            "Epoch [3/40], Validation Accuracy: 76.53%\n",
            "Epoch [4/40], Validation Accuracy: 77.64%\n",
            "Epoch [5/40], Validation Accuracy: 78.11%\n",
            "Epoch [6/40], Validation Accuracy: 78.78%\n",
            "Epoch [7/40], Validation Accuracy: 78.89%\n",
            "Epoch [8/40], Validation Accuracy: 79.53%\n",
            "Epoch [9/40], Validation Accuracy: 79.85%\n",
            "Epoch [10/40], Validation Accuracy: 80.15%\n",
            "Epoch [11/40], Validation Accuracy: 80.31%\n",
            "Epoch [12/40], Validation Accuracy: 80.56%\n",
            "Epoch [13/40], Validation Accuracy: 80.94%\n",
            "Epoch [14/40], Validation Accuracy: 81.00%\n",
            "Epoch [15/40], Validation Accuracy: 81.24%\n",
            "Epoch [16/40], Validation Accuracy: 81.50%\n",
            "Epoch [17/40], Validation Accuracy: 81.50%\n",
            "Epoch [18/40], Validation Accuracy: 81.85%\n",
            "Epoch [19/40], Validation Accuracy: 81.85%\n",
            "Epoch [20/40], Validation Accuracy: 81.99%\n",
            "Epoch [21/40], Validation Accuracy: 81.90%\n",
            "Epoch [22/40], Validation Accuracy: 82.10%\n",
            "Epoch [23/40], Validation Accuracy: 82.28%\n",
            "Epoch [24/40], Validation Accuracy: 82.38%\n",
            "Epoch [25/40], Validation Accuracy: 82.43%\n",
            "Epoch [26/40], Validation Accuracy: 82.44%\n",
            "Epoch [27/40], Validation Accuracy: 82.58%\n",
            "Epoch [28/40], Validation Accuracy: 82.61%\n",
            "Epoch [29/40], Validation Accuracy: 82.67%\n",
            "Epoch [30/40], Validation Accuracy: 82.92%\n",
            "Epoch [31/40], Validation Accuracy: 82.92%\n",
            "Epoch [32/40], Validation Accuracy: 82.93%\n",
            "Epoch [33/40], Validation Accuracy: 82.96%\n",
            "Epoch [34/40], Validation Accuracy: 83.22%\n",
            "Epoch [35/40], Validation Accuracy: 83.25%\n",
            "Epoch [36/40], Validation Accuracy: 83.32%\n",
            "Epoch [37/40], Validation Accuracy: 83.36%\n",
            "Epoch [38/40], Validation Accuracy: 83.38%\n",
            "Epoch [39/40], Validation Accuracy: 83.50%\n",
            "Epoch [40/40], Validation Accuracy: 83.62%\n",
            "Test Accuracy: 83.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "INqO0smVE_L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import bz2\n",
        "from collections import Counter\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUMKqUo7UJ85",
        "outputId": "1ef1caa3-aacb-47f9-e442-e1bdc6153e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = bz2.BZ2File('train.ft.txt.bz2')\n",
        "test_file = bz2.BZ2File('test.ft.txt.bz2')"
      ],
      "metadata": {
        "id": "IBfbGorqUK3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_file = train_file.readlines()\n",
        "test_file = test_file.readlines()"
      ],
      "metadata": {
        "id": "KmWzDWaeUVB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pct = 0.3\n",
        "num_train = int(len(train_file)*pct) #max 3600000\n",
        "num_test = int(len(test_file)*pct) #max 400000\n",
        "train_file = [x.decode('utf-8') for x in train_file[:num_train]]\n",
        "test_file = [x.decode('utf-8') for x in test_file[:num_train]]\n",
        "train_file[1:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKD4fiECUdjN",
        "outputId": "2afa4d02-3190-418a-8da2-28528917081c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
              " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
              " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
              " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting labels from sentences\n",
        "train_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in train_file]\n",
        "train_sentences = [x.split(' ', 1)[1][:-1].lower() for x in train_file]\n",
        "\n",
        "test_labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test_file]\n",
        "test_sentences = [x.split(' ', 1)[1][:-1].lower() for x in test_file]"
      ],
      "metadata": {
        "id": "OVeicQm8UiRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    train_sentences[i] = re.sub('\\d','0',train_sentences[i])\n",
        "\n",
        "for i in range(len(test_sentences)):\n",
        "    test_sentences[i] = re.sub('\\d','0',test_sentences[i])"
      ],
      "metadata": {
        "id": "a8wtCFhtUi1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_sentences)):\n",
        "    if 'www.' in train_sentences[i] or 'http:' in train_sentences[i] or 'https:' in train_sentences[i] or '.com' in train_sentences[i]:\n",
        "        train_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", train_sentences[i])\n",
        "\n",
        "for i in range(len(test_sentences)):\n",
        "    if 'www.' in test_sentences[i] or 'http:' in test_sentences[i] or 'https:' in test_sentences[i] or '.com' in test_sentences[i]:\n",
        "        test_sentences[i] = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", test_sentences[i])"
      ],
      "metadata": {
        "id": "r94INzhsUq7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = Counter()  # Dictionary that will map a word to the number of times it appeared in all the training sentences\n",
        "for i, sentence in enumerate(train_sentences):\n",
        "    # The sentences will be stored as a list of words/tokens\n",
        "    train_sentences[i] = []\n",
        "    for word in nltk.word_tokenize(sentence):  # Tokenizing the words\n",
        "        words.update([word.lower()])  # Converting all the words to lowercase\n",
        "        train_sentences[i].append(word)\n",
        "    if i%20000 == 0:\n",
        "        print(str((i*100)/num_train) + \"% done\")\n",
        "print(\"100% done\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQffsC5PUxqI",
        "outputId": "a74c7e73-3ef6-4423-a11a-6c8e39407fe2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0% done\n",
            "1.8518518518518519% done\n",
            "3.7037037037037037% done\n",
            "5.555555555555555% done\n",
            "7.407407407407407% done\n",
            "9.25925925925926% done\n",
            "11.11111111111111% done\n",
            "12.962962962962964% done\n",
            "14.814814814814815% done\n",
            "16.666666666666668% done\n",
            "18.51851851851852% done\n",
            "20.37037037037037% done\n",
            "22.22222222222222% done\n",
            "24.074074074074073% done\n",
            "25.925925925925927% done\n",
            "27.77777777777778% done\n",
            "29.62962962962963% done\n",
            "31.48148148148148% done\n",
            "33.333333333333336% done\n",
            "35.18518518518518% done\n",
            "37.03703703703704% done\n",
            "38.888888888888886% done\n",
            "40.74074074074074% done\n",
            "42.592592592592595% done\n",
            "44.44444444444444% done\n",
            "46.2962962962963% done\n",
            "48.148148148148145% done\n",
            "50.0% done\n",
            "51.851851851851855% done\n",
            "53.7037037037037% done\n",
            "55.55555555555556% done\n",
            "57.407407407407405% done\n",
            "59.25925925925926% done\n",
            "61.111111111111114% done\n",
            "62.96296296296296% done\n",
            "64.81481481481481% done\n",
            "66.66666666666667% done\n",
            "68.51851851851852% done\n",
            "70.37037037037037% done\n",
            "72.22222222222223% done\n",
            "74.07407407407408% done\n",
            "75.92592592592592% done\n",
            "77.77777777777777% done\n",
            "79.62962962962963% done\n",
            "81.48148148148148% done\n",
            "83.33333333333333% done\n",
            "85.18518518518519% done\n",
            "87.03703703703704% done\n",
            "88.88888888888889% done\n",
            "90.74074074074075% done\n",
            "92.5925925925926% done\n",
            "94.44444444444444% done\n",
            "96.29629629629629% done\n",
            "98.14814814814815% done\n",
            "100% done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing the words that only appear once\n",
        "words = {k:v for k,v in words.items() if v>1}\n",
        "# Sorting the words according to the number of appearances, with the most common word being first\n",
        "words = sorted(words, key=words.get, reverse=True)\n",
        "# Adding padding and unknown to our vocabulary so that they will be assigned an index\n",
        "words = ['_PAD','_UNK'] + words\n",
        "# Dictionaries to store the word to index mappings and vice versa\n",
        "word2idx = {o:i for i,o in enumerate(words)}\n",
        "idx2word = {i:o for i,o in enumerate(words)}\n",
        "#convert the words in the sentences to their corresponding indexes\n",
        "\n",
        "for i, sentence in enumerate(train_sentences):\n",
        "    # Looking up the mapping dictionary and assigning the index to the respective words\n",
        "    train_sentences[i] = [word2idx[word] if word in word2idx else 0 for word in sentence]\n",
        "\n",
        "for i, sentence in enumerate(test_sentences):\n",
        "    # For test sentences, we have to tokenize the sentences as well\n",
        "    test_sentences[i] = [word2idx[word.lower()] if word.lower() in word2idx else 0 for word in nltk.word_tokenize(sentence)]"
      ],
      "metadata": {
        "id": "VA_vTf1Fsb6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#padding the sentences with 0s and shortening the lengthy sentences so that the data can be trained in batches to speed things up\n",
        "\n",
        "# Defining a function that either shortens sentences or pads sentences with 0 to a fixed length\n",
        "def pad_input(sentences, seq_len):\n",
        "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
        "    for ii, review in enumerate(sentences):\n",
        "        if len(review) != 0:\n",
        "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
        "    return features\n",
        "\n",
        "seq_len = 200  # The length that the sentences will be padded/shortened to\n",
        "\n",
        "train_sentences = pad_input(train_sentences, seq_len)\n",
        "test_sentences = pad_input(test_sentences, seq_len)\n",
        "\n",
        "# Converting our labels into numpy arrays\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "1sRWcQSQtIiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split into train/Val/test datasets\n",
        "\n",
        "split_frac = 0.5 # 50% validation, 50% test\n",
        "split_id = int(split_frac * len(test_sentences))\n",
        "val_sentences, test_sentences = test_sentences[:split_id], test_sentences[split_id:]\n",
        "val_labels, test_labels = test_labels[:split_id], test_labels[split_id:]"
      ],
      "metadata": {
        "id": "udKXrxZOtPTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create model with Pytorch\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.nn as nn\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(train_sentences), torch.from_numpy(train_labels))\n",
        "val_data = TensorDataset(torch.from_numpy(val_sentences), torch.from_numpy(val_labels))\n",
        "test_data = TensorDataset(torch.from_numpy(test_sentences), torch.from_numpy(test_labels))\n",
        "\n",
        "batch_size = 400\n",
        "\n",
        "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_data, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-LtLTDukU6YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU available')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('Only CPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7cpujAbVBwh",
        "outputId": "494f7153-6620-40cb-d51f-9f0c9f315cca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentNet(nn.Module):\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        super(SentimentNet, self).__init__()\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.long()\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        out = self.sigmoid(out)\n",
        "\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = out[:,-1]\n",
        "        return out, hidden\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().to(device))\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "7xv0c8d7sFJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(word2idx) + 1\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 512\n",
        "n_layers = 2\n",
        "\n",
        "model = SentimentNet(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "model.to(device)\n",
        "\n",
        "lr=0.005\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "epochs = 2\n",
        "counter = 0\n",
        "print_every = 500\n",
        "clip = 5\n",
        "valid_loss_min = np.Inf\n",
        "\n",
        "model.train()\n",
        "for i in range(epochs):\n",
        "    h = model.init_hidden(batch_size)\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        counter += 1\n",
        "        h = tuple([e.data for e in h])\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        model.zero_grad()\n",
        "        output, h = model(inputs, h)\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        if counter%print_every == 0:\n",
        "            val_h = model.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            model.eval()\n",
        "            for inp, lab in val_loader:\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "                inp, lab = inp.to(device), lab.to(device)\n",
        "                out, val_h = model(inp, val_h)\n",
        "                val_loss = criterion(out.squeeze(), lab.float())\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            model.train()\n",
        "            print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))\n",
        "            if np.mean(val_losses) <= valid_loss_min:\n",
        "                torch.save(model.state_dict(), './state_dict.pt')\n",
        "                print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,np.mean(val_losses)))\n",
        "                valid_loss_min = np.mean(val_losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGzjbLMuVL2O",
        "outputId": "029f5015-da5d-469e-c783-f7caef118983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/2... Step: 500... Loss: 0.223739... Val Loss: 0.206195\n",
            "Validation loss decreased (inf --> 0.206195).  Saving model ...\n",
            "Epoch: 1/2... Step: 1000... Loss: 0.212604... Val Loss: 0.175982\n",
            "Validation loss decreased (0.206195 --> 0.175982).  Saving model ...\n",
            "Epoch: 1/2... Step: 1500... Loss: 0.191558... Val Loss: 0.170314\n",
            "Validation loss decreased (0.175982 --> 0.170314).  Saving model ...\n",
            "Epoch: 1/2... Step: 2500... Loss: 0.171799... Val Loss: 0.174236\n",
            "Epoch: 2/2... Step: 3000... Loss: 0.183870... Val Loss: 0.167538\n",
            "Validation loss decreased (0.170314 --> 0.167538).  Saving model ...\n",
            "Epoch: 2/2... Step: 3500... Loss: 0.156412... Val Loss: 0.170313\n",
            "Epoch: 2/2... Step: 4000... Loss: 0.147273... Val Loss: 0.169157\n",
            "Epoch: 2/2... Step: 4500... Loss: 0.145281... Val Loss: 0.179763\n",
            "Epoch: 2/2... Step: 5000... Loss: 0.143815... Val Loss: 0.179764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the best model\n",
        "model.load_state_dict(torch.load('./state_dict.pt'))\n",
        "\n",
        "test_losses = []\n",
        "num_correct = 0\n",
        "h = model.init_hidden(batch_size)\n",
        "\n",
        "model.eval()\n",
        "for inputs, labels in test_loader:\n",
        "    h = tuple([each.data for each in h])\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    output, h = model(inputs, h)\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    pred = torch.round(output.squeeze())  # Rounds the output to 0/1\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "test_acc = num_correct/len(test_loader.dataset)\n",
        "print(\"Test accuracy: {:.3f}%\".format(test_acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3r4zG66eXYH",
        "outputId": "3b778e18-616a-4dae-b23b-09575d0cc44a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.163\n",
            "Test accuracy: 93.746%\n"
          ]
        }
      ]
    }
  ]
}